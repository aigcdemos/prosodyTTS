# Titleï¼šProsody Injection for LLM-based TTS System

[![Paper](https://img.shields.io/badge/Paper-PDF-red)](link-to-paper.pdf)
[![Conference](https://img.shields.io/badge/Conference-ConferenceName-Year-blue)](conference-link)
[![GitHub stars](https://img.shields.io/github/stars/yourusername/repo?style=social)](https://github.com/yourusername/repo)

## ğŸ“– Abstract

This paper proposes a prosody modeling and injection method for LLM-based Text-to-Speech (TTS) systems. 
The approach incorporates prosodic markers at specific textual positions to enable precise prosody control. 
Notably, it requires no structural modifications to the base TTS model. 
Instead, prosodic information is extracted from the dataset, and the LLM within the TTS system 
is fine-tuned using text-audio pairs enriched with these prosodic markers. 
This process equips the model with the capability to recognize and reproduce prosodic patterns. 
Concurrently, we fine-tune a text-based LLM to convert user-described emotional cues into sequences of prosodic markers and prompts, 
which are then inserted into the input text. Experiments conducted on the VoxBox Chinese dataset 
demonstrate that our method effectively injects prosodic variations into synthesized speech. 
Demo samples are available at [https://github.com/aigcdemos/prosodyTTS]. 

## ğŸ” Contributions

- **1**ï¼šA finer-grained prosody extraction method, namely character-level prosody modeling, which enables precise control over the temporal variation of prosody rather than overall prosody control. Specifically, it analyzes the prosodic variation for each character in a sentence and inserts corresponding prosodic markers at positions where prosodic changes are prominent, e.g., if the fundamental frequency (F0) difference between two adjacent characters exceeds a threshold, a rising marker (for increased F0) or a falling marker (for decreased F0) is added. Based on this method, a dataset with detailed descriptions of prosodic changes was built.
- **2**ï¼šAn LLM fine-tuning method that enables the model to insert fine-grained prosodic control information into the text to be synthesized based on user prompts (e.g., fine-grained emotional changes over time rather than a single overall emotion label), thereby reflecting the temporal variation of prosody.


## ğŸ’¡ Samples

| éŸµå¾‹æ ‡è®°&nbsp;&nbsp;&nbsp;&nbsp; | TTSæ–‡æœ¬ | æ ‡è®°å‰&nbsp;&nbsp;&nbsp;&nbsp; | æ ‡è®°å&nbsp;&nbsp;&nbsp;&nbsp; |
|:--------:|:--------|:------:|:------:|
| **é•¿éŸ³** | æ‹–éŸ³çš„æ‹–â†’å­—åº”è¯¥æŒç»­å¾ˆé•¿æ—¶é—´ã€‚ | [é•¿éŸ³å‰](samples/è´¾å®ç‰_drawl_ori_0.wav) | [é•¿éŸ³å](samples/è´¾å®ç‰_drawl_flow_llm_label_0.wav)|
| **é•¿éŸ³** | ç›´æ’­é—´çš„å®¶äººä»¬ï¼Œæˆ‘â†’ä»¬ç›´æ’­é—´å¸¦æ¥â†’äº†è‹¹æœæœ€æ–°çš„åâ†’ä¸ƒpromaxï¼Œç»™æ‚¨å¸¦æ¥å…¨æ–°çš„ä½¿ç”¨ä½“éªŒã€‚ | [é•¿éŸ³å‰](samples/è´¾å®ç‰_long_drawl_ori_1.wav) | [é•¿éŸ³å](samples/è´¾å®ç‰_long_drawl_flow_llm_label_1.wav) |
| **é‡éŸ³** | è¿™å¥è¯åº”è¯¥æ˜¯ç”¨â†‘é‡éŸ³è¿›è¡Œå¼ºè°ƒã€‚ | [é‡éŸ³å‰](samples/è´¾å®ç‰_accent_ori_2.wav) | [é‡éŸ³å](samples/è´¾å®ç‰_accent_flow_llm_label_2.wav) |
| **å‡è°ƒ** | è¿™å¥è¯åº”è¯¥æ˜¯ç”¨â†—å‡è°ƒçš„è¯­æ°”è¯´çš„ã€‚ | [å‡è°ƒå‰](TTS/samples/è´¾å®ç‰_asc_ori_1.wav) | [å‡è°ƒå](samples/è´¾å®ç‰_asc_flow_llm_label_1.wav) |
| **é™è°ƒ** | è¿™å¥è¯åº”è¯¥æ˜¯ç”¨â†˜é™è°ƒçš„è¯­æ°”è¯´çš„ã€‚ | [é™è°ƒå‰](TTS/samples/è´¾å®ç‰_des_ori_0.wav) | [é™è°ƒå](samples/è´¾å®ç‰_des_flow_llm_label_0.wav) |